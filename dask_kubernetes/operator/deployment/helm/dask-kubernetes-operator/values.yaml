image:
  name: ghcr.io/dask/dask-kubernetes-operator  # Docker image for the operator
  tag: "set-by-chartpress"  # Release version
  pullPolicy: IfNotPresent  # Pull policy

imagePullSecrets: []  # Image pull secrets for private registries
nameOverride: ""  # Override release name (not including random UUID)
fullnameOverride: ""  # Override full release name

serviceAccount:
  create: true  # Create a service account for the operator to use
  annotations: {}  # Annotations to add to the service account
  name: ""  # The name of the service account to use. If not set and create is true, a name is generated using the fullname template.

rbac:
  create: true # Create a Role/ClusterRole needed by the operator and bind it to the service account
  cluster: true # Creates a ClusterRole if true, else create a namespaced Role

podAnnotations: {}  # Extra annotations for the operator pod

podSecurityContext: {}  # Security context for the operator pod
  # fsGroup: 2000

securityContext:  # Security context for the operator container
  capabilities:
    drop:
    - ALL
  runAsNonRoot: true
  runAsUser: 1000
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true

resources: {}  # Resources for the operator pod
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

volumes: []  # Volumes for the operator pod

volumeMounts: []  # Volume mounts for the operator container

nodeSelector: {}  # Node selector

tolerations: []  # Tolerations

affinity: {}  # Affinity

priorityClassName: null  # Priority class

kopfArgs: # Command line flags to pass to kopf on start up
  - --all-namespaces

metrics:
  scheduler:
    enabled: false # Enable scheduler metrics. Pip package [prometheus-client](https://pypi.org/project/prometheus-client/) should be present on scheduler.
    serviceMonitor:
      enabled: false # Enable scheduler servicemonitor.
      namespace: "" # Deploy servicemonitor in different namespace, e.g. monitoring.
      namespaceSelector: {} # Selector to select which namespaces the Endpoints objects are discovered from.
      # Default: scrape .Release.Namespace only
      # To scrape all, use the following:
      # namespaceSelector:
      #   any: true
      additionalLabels: {} # Additional labels to add to the ServiceMonitor metadata.
      interval: 15s # Interval at which metrics should be scraped.
      jobLabel: "" # The label to use to retrieve the job name from.
      targetLabels: # TargetLabels transfers labels on the Kubernetes Service onto the target.
        - dask.org/cluster-name
      metricRelabelings: [] # MetricRelabelConfigs to apply to samples before ingestion.
  worker:
    enabled: false # Enable workers metrics. Pip package [prometheus-client](https://pypi.org/project/prometheus-client/) should be present on workers.
    podMonitor:
      enabled: false # Enable workers podmonitor
      namespace: "" # Deploy podmonitor in different namespace, e.g. monitoring.
      namespaceSelector: {} # Selector to select which namespaces the Endpoints objects are discovered from.
      # Default: scrape .Release.Namespace only
      # To scrape all, use the following:
      # namespaceSelector:
      #   any: true
      # metrics will apply to the additional worker groups as well
      additionalLabels: {} # Additional labels to add to the PodMonitor metadata.
      interval: 15s # Interval at which metrics should be scraped.
      jobLabel: "" # The label to use to retrieve the job name from.
      podTargetLabels:  # PodTargetLabels transfers labels on the Kubernetes Pod onto the target.
        - dask.org/cluster-name
        - dask.org/workergroup-name
      metricRelabelings: [] # MetricRelabelConfigs to apply to samples before ingestion.

workerAllocation:
  size: null
  delay: null
